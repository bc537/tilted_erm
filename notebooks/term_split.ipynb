{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()\n",
    "features = iris_data.data\n",
    "labels = iris_data.target\n",
    "features = MinMaxScaler().fit_transform(features)\n",
    "df = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "df[\"class\"] = pd.Series(iris_data.target)\n",
    "random_seed = 123\n",
    "k = 5\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_seed)\n",
    "train_index_total = []\n",
    "test_index_total = []\n",
    "for i, (train_index, test_index) in enumerate(skf.split(features, labels)):\n",
    "    train_index_total.append(train_index)\n",
    "    test_index_total.append(test_index)\n",
    "\n",
    "train_index_total = np.reshape(train_index_total, (k, -1)).T\n",
    "test_index_total = np.reshape(test_index_total, (k, -1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy array to a DataFrame\n",
    "train_index_df = pd.DataFrame(train_index_total)\n",
    "test_index_df = pd.DataFrame(test_index_total)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "train_index_df.to_excel(\"data/train_index_total.xlsx\", index=False, header=False)\n",
    "test_index_df.to_excel(\"data/test_index_total.xlsx\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = [1, 2, 3, 4, 5]\n",
    "for k in split:\n",
    "    split = k\n",
    "    k_2 = 5\n",
    "    train_index_2 = train_index_total[:, split - 1]\n",
    "    test_index_2 = test_index_total[:, split - 1]\n",
    "    skf_2 = StratifiedKFold(n_splits=k_2, shuffle=True, random_state=random_seed)\n",
    "\n",
    "    train_features = features[train_index_2]\n",
    "    train_labels = labels[train_index_2]\n",
    "    train_index_2_keep_total = []\n",
    "    train_index_2_exclude_total = []\n",
    "    for i, (train_index_2_keep, train_index_2_exclude) in enumerate(skf_2.split(train_features, train_labels)):\n",
    "        train_index_2_keep_total.append(train_index_2_keep)\n",
    "        train_index_2_exclude_total.append(train_index_2_exclude)\n",
    "    train_index_2_keep_total = train_index_2_keep_total[0]\n",
    "    train_index_2_exclude_total = train_index_2_exclude_total[0]\n",
    "\n",
    "    test_features = features[test_index_2]\n",
    "    test_labels = labels[test_index_2]\n",
    "    test_index_2_keep_total = []\n",
    "    test_index_2_exclude_total = []\n",
    "    for i, (test_index_2_keep, test_index_2_exclude) in enumerate(skf_2.split(test_features, test_labels)):\n",
    "        test_index_2_keep_total.append(test_index_2_keep)\n",
    "        test_index_2_exclude_total.append(test_index_2_exclude)\n",
    "    test_index_2_keep_total = test_index_2_keep_total[0]\n",
    "    test_index_2_exclude_total = test_index_2_exclude_total[0]\n",
    "\n",
    "    for i in range(len(train_index_2_keep_total)):\n",
    "        f = train_features[train_index_2_keep_total[i]]\n",
    "        for j in range(len(labels)):\n",
    "            if np.array_equal(f, features[j]):\n",
    "                train_index_2_keep_total[i] = j\n",
    "                break\n",
    "\n",
    "    for i in range(len(train_index_2_exclude_total)):\n",
    "        f = train_features[train_index_2_exclude_total[i]]\n",
    "        for j in range(len(labels)):\n",
    "            if np.array_equal(f, features[j]):\n",
    "                train_index_2_exclude_total[i] = j\n",
    "                break\n",
    "\n",
    "    for i in range(len(test_index_2_keep_total)):\n",
    "        f = test_features[test_index_2_keep_total[i]]\n",
    "        for j in range(len(labels)):\n",
    "            if np.array_equal(f, features[j]):\n",
    "                test_index_2_keep_total[i] = j\n",
    "                break\n",
    "\n",
    "    for i in range(len(test_index_2_exclude_total)):\n",
    "        f = test_features[test_index_2_exclude_total[i]]\n",
    "        for j in range(len(labels)):\n",
    "            if np.array_equal(f, features[j]):\n",
    "                test_index_2_exclude_total[i] = j\n",
    "                break\n",
    "\n",
    "    train_index_2_exclude_total_class0 = train_index_2_exclude_total[0:len(train_index_2_exclude_total)//3]\n",
    "    train_index_2_exclude_total_class1 = train_index_2_exclude_total[len(train_index_2_exclude_total)//3:2*len(train_index_2_exclude_total)//3]\n",
    "    train_index_2_exclude_total_class2 = train_index_2_exclude_total[2*len(train_index_2_exclude_total)//3:]\n",
    "    test_index_2_exclude_total_class0 = test_index_2_exclude_total[0:len(test_index_2_exclude_total)//3]\n",
    "    test_index_2_exclude_total_class1 = test_index_2_exclude_total[len(test_index_2_exclude_total)//3:2*len(test_index_2_exclude_total)//3]\n",
    "    test_index_2_exclude_total_class2 = test_index_2_exclude_total[2*len(test_index_2_exclude_total)//3:]\n",
    "\n",
    "    train_index_2_combined_class0 = np.sort(np.concatenate((train_index_2_keep_total, train_index_2_exclude_total_class0)))\n",
    "    train_index_2_combined_class1 = np.sort(np.concatenate((train_index_2_keep_total, train_index_2_exclude_total_class1)))\n",
    "    train_index_2_combined_class2 = np.sort(np.concatenate((train_index_2_keep_total, train_index_2_exclude_total_class2)))\n",
    "    test_index_2_combined_class0 = np.sort(np.concatenate((test_index_2_keep_total, test_index_2_exclude_total_class0)))\n",
    "    test_index_2_combined_class1 = np.sort(np.concatenate((test_index_2_keep_total, test_index_2_exclude_total_class1)))\n",
    "    test_index_2_combined_class2 = np.sort(np.concatenate((test_index_2_keep_total, test_index_2_exclude_total_class2)))\n",
    "\n",
    "    train_index_2_combined = (np.concatenate((train_index_2_combined_class0, train_index_2_combined_class1, train_index_2_combined_class2)))\n",
    "    train_index_2_combined = np.reshape(train_index_2_combined, (3, -1)).T\n",
    "    test_index_2_combined = (np.concatenate((test_index_2_combined_class0, test_index_2_combined_class1, test_index_2_combined_class2)))\n",
    "    test_index_2_combined = np.reshape(test_index_2_combined, (3, -1)).T\n",
    "\n",
    "    train_index_2_combined_df = pd.DataFrame(train_index_2_combined)\n",
    "    test_index_2_combined_df = pd.DataFrame(test_index_2_combined)\n",
    "\n",
    "    train_index_2_combined_df.to_excel(f\"data/train_index_split{split}_new.xlsx\", index=False, header=False)\n",
    "    test_index_2_combined_df.to_excel(f\"data/test_index_split{split}_new.xlsx\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = [1, 2, 3, 4, 5]\n",
    "for k in split:\n",
    "    split = k\n",
    "    k_2 = 5\n",
    "    train_index_2 = train_index_total[:, split - 1]\n",
    "    test_index_2 = test_index_total[:, split - 1]\n",
    "    skf_2 = StratifiedKFold(n_splits=k_2, shuffle=True, random_state=random_seed)\n",
    "\n",
    "    train_features = features[train_index_2]\n",
    "    train_labels = labels[train_index_2]\n",
    "    train_index_2_keep_total = []\n",
    "    train_index_2_exclude_total = []\n",
    "    for i, (train_index_2_exclude, train_index_2_keep) in enumerate(skf_2.split(train_features, train_labels)):\n",
    "        train_index_2_exclude_total.append(train_index_2_exclude)\n",
    "        train_index_2_keep_total.append(train_index_2_keep)\n",
    "    train_index_2_keep_total = train_index_2_keep_total[0]\n",
    "    train_index_2_exclude_total = train_index_2_exclude_total[0]\n",
    "\n",
    "    test_features = features[test_index_2]\n",
    "    test_labels = labels[test_index_2]\n",
    "    test_index_2_keep_total = []\n",
    "    test_index_2_exclude_total = []\n",
    "    for i, (test_index_2_exclude, test_index_2_keep) in enumerate(skf_2.split(test_features, test_labels)):\n",
    "        test_index_2_exclude_total.append(test_index_2_exclude)\n",
    "        test_index_2_keep_total.append(test_index_2_keep)\n",
    "    test_index_2_keep_total = test_index_2_keep_total[0]\n",
    "    test_index_2_exclude_total = test_index_2_exclude_total[0]\n",
    "\n",
    "    for i in range(len(train_index_2_keep_total)):\n",
    "        f = train_features[train_index_2_keep_total[i]]\n",
    "        for j in range(len(labels)):\n",
    "            if np.array_equal(f, features[j]):\n",
    "                train_index_2_keep_total[i] = j\n",
    "                break\n",
    "\n",
    "    for i in range(len(train_index_2_exclude_total)):\n",
    "        f = train_features[train_index_2_exclude_total[i]]\n",
    "        for j in range(len(labels)):\n",
    "            if np.array_equal(f, features[j]):\n",
    "                train_index_2_exclude_total[i] = j\n",
    "                break\n",
    "\n",
    "    for i in range(len(test_index_2_keep_total)):\n",
    "        f = test_features[test_index_2_keep_total[i]]\n",
    "        for j in range(len(labels)):\n",
    "            if np.array_equal(f, features[j]):\n",
    "                test_index_2_keep_total[i] = j\n",
    "                break\n",
    "\n",
    "    for i in range(len(test_index_2_exclude_total)):\n",
    "        f = test_features[test_index_2_exclude_total[i]]\n",
    "        for j in range(len(labels)):\n",
    "            if np.array_equal(f, features[j]):\n",
    "                test_index_2_exclude_total[i] = j\n",
    "                break\n",
    "\n",
    "    train_index_2_exclude_total_class0 = train_index_2_exclude_total[0:len(train_index_2_exclude_total)//3]\n",
    "    train_index_2_exclude_total_class1 = train_index_2_exclude_total[len(train_index_2_exclude_total)//3:2*len(train_index_2_exclude_total)//3]\n",
    "    train_index_2_exclude_total_class2 = train_index_2_exclude_total[2*len(train_index_2_exclude_total)//3:]\n",
    "\n",
    "    test_index_2_exclude_total_class0 = test_index_2_exclude_total[0:len(test_index_2_exclude_total)//3]\n",
    "    test_index_2_exclude_total_class1 = test_index_2_exclude_total[len(test_index_2_exclude_total)//3:2*len(test_index_2_exclude_total)//3]\n",
    "    test_index_2_exclude_total_class2 = test_index_2_exclude_total[2*len(test_index_2_exclude_total)//3:]\n",
    "\n",
    "    train_index_2_combined_class0 = np.sort(np.concatenate((train_index_2_keep_total, train_index_2_exclude_total_class0)))\n",
    "    train_index_2_combined_class1 = np.sort(np.concatenate((train_index_2_keep_total, train_index_2_exclude_total_class1)))\n",
    "    train_index_2_combined_class2 = np.sort(np.concatenate((train_index_2_keep_total, train_index_2_exclude_total_class2)))\n",
    "    test_index_2_combined_class0 = np.sort(np.concatenate((test_index_2_keep_total, test_index_2_exclude_total_class0)))\n",
    "    test_index_2_combined_class1 = np.sort(np.concatenate((test_index_2_keep_total, test_index_2_exclude_total_class1)))\n",
    "    test_index_2_combined_class2 = np.sort(np.concatenate((test_index_2_keep_total, test_index_2_exclude_total_class2)))\n",
    "\n",
    "    train_index_2_combined = (np.concatenate((train_index_2_combined_class0, train_index_2_combined_class1, train_index_2_combined_class2)))\n",
    "    train_index_2_combined = np.reshape(train_index_2_combined, (3, -1)).T\n",
    "    test_index_2_combined = (np.concatenate((test_index_2_combined_class0, test_index_2_combined_class1, test_index_2_combined_class2)))\n",
    "    test_index_2_combined = np.reshape(test_index_2_combined, (3, -1)).T\n",
    "\n",
    "    train_index_2_combined_df = pd.DataFrame(train_index_2_combined)\n",
    "    test_index_2_combined_df = pd.DataFrame(test_index_2_combined)\n",
    "\n",
    "    train_index_2_combined_df.to_excel(f\"data/train_index_split{split}.xlsx\", index=False, header=False)\n",
    "    test_index_2_combined_df.to_excel(f\"data/test_index_split{split}.xlsx\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qc1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
