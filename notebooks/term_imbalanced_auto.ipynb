{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from qiskit.circuit.library import RealAmplitudes, TwoLocal\n",
    "from qiskit_algorithms.optimizers import COBYLA, L_BFGS_B\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier, VQC\n",
    "from qiskit_machine_learning.utils.loss_functions.loss_functions import Loss\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from term_loss.loss import L1Loss_ERM, L1Loss_TERM, L2Loss_ERM, L2Loss_TERM, CrossEntropyLoss_ERM, CrossEntropyLoss_TERM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()\n",
    "features = iris_data.data\n",
    "labels = iris_data.target\n",
    "features = MinMaxScaler(feature_range=(-np.pi, np.pi)).fit_transform(features)\n",
    "split = 5\n",
    "excess_class = 2\n",
    "train_index_total = pd.read_excel(f\"data/train_index_split{split}.xlsx\", header=None).to_numpy()\n",
    "test_index_total = pd.read_excel(f\"data/test_index_split{split}.xlsx\", header=None).to_numpy()\n",
    "train_index = train_index_total[:, excess_class]\n",
    "test_index = test_index_total[:, excess_class]\n",
    "train_features = features[train_index]\n",
    "train_labels = labels[train_index]\n",
    "test_features = features[test_index]\n",
    "test_labels = labels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 Train Score: 0.9107142857142857 Test Score: 0.9285714285714286\n",
      "Iteration 2 Train Score: 0.8571428571428571 Test Score: 0.7857142857142857\n",
      "Iteration 3 Train Score: 0.9107142857142857 Test Score: 0.9285714285714286\n",
      "Iteration 4 Train Score: 0.8571428571428571 Test Score: 0.7857142857142857\n",
      "Iteration 5 Train Score: 0.8571428571428571 Test Score: 0.7857142857142857\n",
      "Iteration 6 Train Score: 0.8392857142857143 Test Score: 0.7857142857142857\n",
      "Iteration 7 Train Score: 0.9285714285714286 Test Score: 0.7142857142857143\n",
      "Iteration 8 Train Score: 0.9107142857142857 Test Score: 0.9285714285714286\n",
      "Iteration 9 Train Score: 0.8035714285714286 Test Score: 0.7857142857142857\n",
      "Iteration 10 Train Score: 0.8928571428571429 Test Score: 0.9285714285714286\n",
      "Mean Train Score: 0.8767857142857143 Mean Test Score: 0.8357142857142857\n",
      "Iteration 1 Train Score: 0.9285714285714286 Test Score: 0.9285714285714286\n",
      "Iteration 2 Train Score: 0.9285714285714286 Test Score: 0.8571428571428571\n",
      "Iteration 3 Train Score: 0.9642857142857143 Test Score: 0.9285714285714286\n",
      "Iteration 4 Train Score: 0.9464285714285714 Test Score: 0.9285714285714286\n",
      "Iteration 5 Train Score: 0.9642857142857143 Test Score: 0.9285714285714286\n",
      "Iteration 6 Train Score: 0.9107142857142857 Test Score: 0.8571428571428571\n",
      "Iteration 7 Train Score: 0.9464285714285714 Test Score: 0.9285714285714286\n",
      "Iteration 8 Train Score: 0.9642857142857143 Test Score: 0.8571428571428571\n",
      "Iteration 9 Train Score: 0.9464285714285714 Test Score: 0.9285714285714286\n",
      "Iteration 10 Train Score: 0.9285714285714286 Test Score: 0.7857142857142857\n",
      "Mean Train Score: 0.9428571428571428 Mean Test Score: 0.8928571428571429\n",
      "Iteration 1 Train Score: 1.0 Test Score: 0.9285714285714286\n",
      "Iteration 2 Train Score: 1.0 Test Score: 1.0\n",
      "Iteration 3 Train Score: 1.0 Test Score: 0.9285714285714286\n",
      "Iteration 4 Train Score: 0.9642857142857143 Test Score: 0.9285714285714286\n",
      "Iteration 5 Train Score: 1.0 Test Score: 1.0\n",
      "Iteration 6 Train Score: 0.9821428571428571 Test Score: 0.9285714285714286\n",
      "Iteration 7 Train Score: 0.9821428571428571 Test Score: 0.9285714285714286\n",
      "Iteration 8 Train Score: 1.0 Test Score: 0.9285714285714286\n",
      "Iteration 9 Train Score: 1.0 Test Score: 0.9285714285714286\n",
      "Iteration 10 Train Score: 0.9821428571428571 Test Score: 1.0\n",
      "Mean Train Score: 0.9910714285714286 Mean Test Score: 0.95\n"
     ]
    }
   ],
   "source": [
    "#Automated testing\n",
    "num_points = 10\n",
    "total_train = np.zeros(num_points)\n",
    "total_test = np.zeros(num_points)\n",
    "ansatz_reps_list = [1,2,3]\n",
    "\n",
    "for j in ansatz_reps_list:\n",
    "    for i in range(num_points):\n",
    "        num_qubits = features.shape[1]\n",
    "        feature_reps = 1\n",
    "        ansatz_reps = j\n",
    "        maxiter = 100\n",
    "        t = 1\n",
    "        feature_map = RealAmplitudes(num_qubits=num_qubits, entanglement=\"linear\", parameter_prefix='x', reps=feature_reps, skip_final_rotation_layer=True)\n",
    "        ansatz = RealAmplitudes(num_qubits=num_qubits, reps=ansatz_reps, entanglement='linear', skip_final_rotation_layer=False)\n",
    "        initial_point = (np.random.random(ansatz.num_parameters) - 0.5) * 2 * np.pi \n",
    "\n",
    "        # construct neural network classifier\n",
    "        vqc = VQC(\n",
    "            feature_map=feature_map,\n",
    "            ansatz=ansatz,\n",
    "            optimizer=L_BFGS_B(maxiter=maxiter),\n",
    "            loss = L2Loss_TERM(t=t),\n",
    "            initial_point = initial_point\n",
    "        )\n",
    "        erm_string = f'term_t{t}'\n",
    "\n",
    "        newpath = f'/Users/choyboy/Documents/Python/TERM/vqc_data/lbfgs/l2_loss/{erm_string}/split{split}_class{excess_class}/a{ansatz_reps}'\n",
    "        if not os.path.exists(newpath):\n",
    "            os.makedirs(newpath)\n",
    "\n",
    "        vqc.fit(train_features, train_labels)\n",
    "        train_score = vqc.score(train_features, train_labels)\n",
    "        test_score = vqc.score(test_features, test_labels)\n",
    "        total_train[i] = train_score\n",
    "        total_test[i] = test_score\n",
    "        print('Iteration', i+1, 'Train Score:', train_score, 'Test Score:', test_score)\n",
    "        vqc.save(f'{newpath}/point{i+1}')\n",
    "\n",
    "    # save total_train and total_test into excel files\n",
    "    mean_train = np.mean(total_train)\n",
    "    mean_test = np.mean(total_test)\n",
    "    print('Mean Train Score:', mean_train, 'Mean Test Score:', mean_test)\n",
    "\n",
    "    df_results = pd.DataFrame({'Train Accuracy': total_train, 'Test Accuracy': total_test})\n",
    "    df_results.to_excel(f'{newpath}/results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.9524999999999999 Mean Test Score: 0.9499999999999998\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(total_train)\n",
    "mean_test = np.mean(total_test)\n",
    "print('Mean Train Score:', mean_train, 'Mean Test Score:', mean_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qc1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
